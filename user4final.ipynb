{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53883227-a1ca-40c7-9075-7db505293df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec6e568-bd10-4c67-8bc5-c75816fb2e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95275/3606502650.py:7: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../shared_documents/pairs_cleaned.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfBen = pd.read_excel(\"../shared_data_read_only/Data/Article1/Hackaton_Benevoles_JPMORGAN.xlsx\")\n",
    "dfBin = pd.read_excel(\"../shared_data_read_only/Data/Article1/Hackaton_Binomes_JPMORGAN.xlsx\")\n",
    "dfJeu = pd.read_excel(\"../shared_data_read_only/Data/Article1/Hackaton_Jeunes_JPMORGAN.xlsx\")\n",
    "\n",
    "df = pd.read_csv(\"../shared_documents/pairs_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4497467b-7316-47c8-8f18-b99ba4b4d732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['y_true'] = df['binome_statut'].isin(['COMPLETED', 'ACTIVE']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fedd2c-a84f-4efc-9200-3685de46c06a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'registration_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'registration_date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 1) registration_date -> days_since_registration\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df_work[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistration_date\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf_work\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregistration_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m ref_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mnormalize()\n\u001b[1;32m      7\u001b[0m df_work[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdays_since_registration\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (ref_date \u001b[38;5;241m-\u001b[39m df_work[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregistration_date\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdays\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'registration_date'"
     ]
    }
   ],
   "source": [
    "df_work = df.copy()\n",
    "\n",
    "# 1) registration_date -> days_since_registration\n",
    "import pandas as pd, numpy as np\n",
    "df_work[\"registration_date\"] = pd.to_datetime(df_work[\"registration_date\"], errors=\"coerce\")\n",
    "ref_date = pd.Timestamp.today().normalize()\n",
    "df_work[\"days_since_registration\"] = (ref_date - df_work[\"registration_date\"]).dt.days\n",
    "num_cols = [\"average_grade\",\"engagement_score\",\"days_since_registration\"]\n",
    "cat_cols = [\"workfield\",\"field_of_study\",\"study_level\",\"degree\",\"needs\",\n",
    "            \"program\",\"desired_exchange_frequency\",\"binome_statut\"]\n",
    "id_cols  = [c for c in [\"binome_id\",\"mentor_id\",\"mentee_id\"] if c in df_work.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380ff1c-afe2-4778-86ff-b79b0d281798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'binome_statut', 'binome_acceptance_delay', 'binome_date_update_statut',\n",
    "    'workfield', 'current_role', 'needs_to_address_mentor',\n",
    "    'field_of_study', 'study_level', 'degree', 'needs_to_address_mentee',\n",
    "    'average_grade', 'program', 'engagement_score',\n",
    "    'registration_date_mentee', 'desired_exchange_frequency', 'hobby',\n",
    "    'project_confidence_level', 'project_development_level',\n",
    "    'binome_score_clean'\n",
    "]\n",
    "X = df[cols].copy()\n",
    "\n",
    "X = X.fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "# Suppose we want to keep top 5 PCs\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(f\"Cumulative variance: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "\n",
    "# Combine into a DataFrame\n",
    "pca_cols = [f\"PC{i}\" for i in range(1, 4)]\n",
    "df_pca_5 = pd.DataFrame(X_pca, columns=pca_cols)\n",
    "\n",
    "# Optionally attach to your main dataframe\n",
    "df_out = pd.concat([df.reset_index(drop=True), df_pca_5], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91d250-f413-45f7-8c38-7e35658f9ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Fit PCA with 5 components\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(f\"Cumulative variance: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "\n",
    "# Combine PCA results into a DataFrame\n",
    "pca_cols = [f\"PC{i}\" for i in range(1, 4)]\n",
    "df_pca_5 = pd.DataFrame(X_pca, columns=pca_cols)\n",
    "\n",
    "# Optionally attach to your main dataframe\n",
    "df_out = pd.concat([df.reset_index(drop=True), df_pca_5], axis=1)\n",
    "\n",
    "# Save outputs\n",
    "df_out.to_csv(\"pca_5components_output.csv\", index=False)\n",
    "\n",
    "print(\"âœ… PCA results saved to 'pca_5components_output.csv'\")\n",
    "print(df_pca_5.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89151c30-a00b-46e2-8b78-f5a93cb13e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_names = X.select_dtypes(include=['float64','int64']).columns\n",
    "\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    index=feature_names,\n",
    "    columns=[f'PC{i+1}' for i in range(pca.n_components_)]\n",
    ")\n",
    "\n",
    "TOP = 5\n",
    "for pc in loadings.columns:\n",
    "    print(f\"\\nTop {TOP} features driving {pc}:\")\n",
    "    print(loadings[pc].abs().sort_values(ascending=False).head(TOP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff0426e-bca1-4b6e-adf4-184ab556518e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def top5_mentors_for_mentee(\n",
    "    mentee_row: pd.Series,\n",
    "    dfMentors: pd.DataFrame,\n",
    "    rf_model,\n",
    "    a_post: float,\n",
    "    b_post: float,\n",
    "    scaler,\n",
    "    feature_cols: list,\n",
    "    num_cols: list,\n",
    "    cat_cols: list,\n",
    "    mentor_id_col: str = \"mentor_id\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given a mentee row, score all mentors and return top-5 by calibrated success probability.\n",
    "    \n",
    "    mentee_row: Single mentee (pd.Series) with raw columns (same schema as training)\n",
    "    dfMentors: All mentors (pd.DataFrame)\n",
    "    rf_model: Trained RandomForestClassifier\n",
    "    a_post, b_post: Posterior means from Bayesian calibration (logit calibration)\n",
    "    scaler: Fitted StandardScaler for numeric columns\n",
    "    feature_cols: Final feature columns used in training (order matters)\n",
    "    num_cols: Numeric feature list used in training (after prefixing if you used prefixes)\n",
    "    cat_cols: Categorical columns to one-hot encode (raw names before prefixing)\n",
    "    mentor_id_col: Column name that identifies mentors in dfMentors\n",
    "    \n",
    "    Returns: DataFrame with [mentor_id, prob] sorted descending, top-5 rows.\n",
    "    \"\"\"\n",
    "    # --- 1) Prefix and broadcast mentee features to all mentors ---\n",
    "    mentee_pref = mentee_row.add_prefix(\"mentee_\")\n",
    "    mentors_pref = dfMentors.add_prefix(\"mentor_\").copy()\n",
    "    \n",
    "    # Repeat mentee fields to match mentors' length\n",
    "    mentee_block = pd.DataFrame([mentee_pref.values] * len(mentors_pref), columns=mentee_pref.index)\n",
    "    pair_df = pd.concat([mentors_pref.reset_index(drop=True), mentee_block.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # --- 2) Build feature matrix exactly like in training ---\n",
    "    # Ensure numeric columns exist and are numeric\n",
    "    for c in num_cols:\n",
    "        if c not in pair_df:\n",
    "            pair_df[c] = 0.0\n",
    "        pair_df[c] = pd.to_numeric(pair_df[c], errors='coerce').fillna(0.0)\n",
    "\n",
    "    # One-hot encode categorical cols (both mentor_* and mentee_* variants may exist)\n",
    "    # cat_cols are raw names; we expand to prefixed forms if present\n",
    "    expanded_cats = []\n",
    "    for raw in cat_cols:\n",
    "        mc = \"mentor_\" + raw\n",
    "        tc = \"mentee_\" + raw\n",
    "        if mc in pair_df.columns: expanded_cats.append(mc)\n",
    "        if tc in pair_df.columns: expanded_cats.append(tc)\n",
    "\n",
    "    if expanded_cats:\n",
    "        pair_df = pd.get_dummies(pair_df, columns=expanded_cats, drop_first=True)\n",
    "\n",
    "    # Add any missing columns expected by the model; keep exact order\n",
    "    for col in feature_cols:\n",
    "        if col not in pair_df:\n",
    "            pair_df[col] = 0\n",
    "    pair_X = pair_df[feature_cols].copy()\n",
    "\n",
    "    # Standardize numeric columns using the training scaler\n",
    "    # (Assumes scaler was fit only on num_cols)\n",
    "    pair_X[num_cols] = scaler.transform(pair_X[num_cols])\n",
    "\n",
    "    # --- 3) Random Forest probability for each mentor ---\n",
    "    rf_prob = rf_model.predict_proba(pair_X)[:, 1]\n",
    "    rf_logit = np.log(np.clip(rf_prob, 1e-6, 1-1e-6) / np.clip(1-rf_prob, 1e-6, 1-1e-6))\n",
    "\n",
    "    # --- 4) Bayesian calibration (Platt with posterior means) ---\n",
    "    prob_cal = 1.0 / (1.0 + np.exp(-(a_post + b_post * rf_logit)))\n",
    "\n",
    "    # --- 5) Return top-5 mentors with probabilities ---\n",
    "    out = pd.DataFrame({\n",
    "        \"mentor_id\": dfMentors[mentor_id_col].values,\n",
    "        \"prob\": prob_cal\n",
    "    }).sort_values(\"prob\", ascending=False).head(5).reset_index(drop=True)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4881122-27dc-4cf3-99b6-86c10a7c87ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mentee_row = dfJeu.iloc[0]\n",
    "mentee_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2bffc-947f-48f1-9194-9baa6ea9e90e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Temporary example values (replace with real posterior means)\n",
    "a_post = -0.2\n",
    "b_post = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc8686-88aa-478b-aece-f840b0a08175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = (\n",
    "    dfBin.merge(dfJeu, on=\"mentee_id\", how=\"left\")\n",
    "         .merge(dfBen, on=\"mentor_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "num_cols = ['binome_score', 'binome_acceptance_delay',\n",
    "            'engagement_score', 'project_confidence_level', 'average_grade']\n",
    "cat_cols = ['workfield', 'current_role', 'field_of_study', 'needs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02241b22-7198-4d52-9a13-7358df6f5347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top5 = top5_mentors_for_mentee(\n",
    "    mentee_row = mentee_row,       # one mentee row\n",
    "    dfMentors  = dfBen,            # full mentor dataframe\n",
    "    rf_model   = rf,               # trained RandomForest\n",
    "    a_post     = a_post,           # Bayesian calibration intercept\n",
    "    b_post     = b_post,           # Bayesian calibration slope\n",
    "    scaler     = scaler,           # StandardScaler used in training\n",
    "    feature_cols = X_rf.columns,   # same feature order as training\n",
    "    num_cols   = [\n",
    "        'mentor_engagement_score',\n",
    "        'mentee_engagement_score',\n",
    "        'mentee_project_confidence_level',\n",
    "        'mentee_project_development_level'\n",
    "    ],\n",
    "    cat_cols   = [\n",
    "        'study_level',\n",
    "        'field_of_study',\n",
    "        'workfield',\n",
    "        'degree',\n",
    "        'program',\n",
    "        'hobby'\n",
    "    ],\n",
    "    mentor_id_col = \"mentor_id\"\n",
    ")\n",
    "\n",
    "print(top5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2972b8-49af-469b-968f-30cd2dc04632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
